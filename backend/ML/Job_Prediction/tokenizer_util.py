def custom_tokenizer(text):
    return text.split(",")
